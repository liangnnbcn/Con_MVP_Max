# Con_MVP_Max



import pandas as pdimport numpy as npimport scipy.optimize as optimport matplotlib.pyplot as plt
target = "HSI"rf = 0.005down = 0.005up = 0.08T = 246
#%%from datetime import datetimedef datelist(beginDate, endDate):    # beginDate, endDate是形如‘20160601’的字符串或datetime格式    date_l=[datetime.strftime(x,'%Y%m%d') for x in list(pd.date_range(start=beginDate, end=endDate))]    return date_ld1 = '20140101'd2 = '20171101'datelist = datelist(d1, d2)
stock_list= pd.DataFrame([np.nan] * np.ones((50,1)))stock_name= pd.DataFrame([np.nan] * np.ones((50,1)))
import osfor i in datelist:    path_list = "/Users/44091781/Desktop/HSIL/Daniel/3-Operation/list name data/"        name =  target + "_opn_con_" + i +".csv"         path_hsi_list = path_list + name        if os.path.exists(path_hsi_list) == True:                data1 = pd.read_csv(path_hsi_list)                if i == datelist[0]:                        stock_list =  data1.iloc[0:50,4:5]                        stock_list.columns = [i]                  stock_name = data1.iloc[0:50,9:10]          else:                        stock_list_add = data1.iloc[0:50,4:5]                        stock_list_add.columns = [i]                   stock_name_add = data1.iloc[0:50,9:10]              stock_name_add.columns = [i]            stock_list = pd.concat([stock_list,stock_list_add],axis=1)              stock_name = pd.concat([stock_name,stock_name_add],axis=1)  
stock_list = stock_list.iloc[:,1:]     stock_name = stock_name.iloc[:,1:]     
#stock_list clearstock_list_dif= stock_list.iloc[:,0:1]for i in range(len(stock_list.T)-1):    if np.sum(stock_list.iloc[:,i] - stock_list.iloc[:,i+1]) !=0:         stock_list_dif = pd.concat([stock_list_dif,stock_list.iloc[:,i+1]],axis=1)
for i in range(len(stock_list_dif.T)):    a = len(set(stock_list_dif.iloc[:,i]))    if a !=50:        stock_list_dif.iloc[a:,i] =np.nan  # （1） 如果不满足 50个，后面的为NANstock_list_dif[(stock_list_dif)>10000] =np.nan  # （2） 还有代码是99999stock_list_dif = pd.concat([stock_list_dif.iloc[:,0:1],stock_list_dif.iloc[:,2:]],axis=1) # （3） 剔出腾讯2988的公司行为stock_list_dif = pd.concat([stock_list_dif.iloc[:,0:3],stock_list_dif.iloc[:,4:]],axis=1) # （4） 一列重复 ，保持49个股stock_list_dif = pd.concat([stock_list_dif.iloc[:,0:5],stock_list_dif.iloc[:,6:]],axis=1) # （5） 一列多余“亲亲食品” ，保持51个股#（6）有两列是49个个股 ，一个是和记黄埔，一个是百里国际 ====设置算法设计到49个股票的  #（6） 长实集团 直接进入。替代和记黄埔 
#STOCK_LIST  TOTAL  SETcode = stock_list_dif.iloc[:,0:1]code_list = list(set(code.iloc[:,0]))for i in range(len(stock_list_dif.T)-1):    code2 = stock_list_dif.iloc[:,i+1:i+2].dropna()    code_list2 = list(set(code2.iloc[:,0]))    code_list.extend(code_list2)code_set = pd.DataFrame(list(set(code_list)))code_set.columns = ['stock code']code_set = code_set.sort_values(by ='stock code',axis=0,ascending=True)
path_out1 = "/Users/44091781/Desktop/HSIL/Daniel/3-Operation/index/0-"+target+"stock_list.xlsx"    code_set.to_excel(path_out1)
#stock_name list connection 暂时人工对照l_stock_list = len(stock_list_dif)l_stock_list_2 = len(stock_list_dif.T)stock_list_change = pd.DataFrame(0 * np.ones((l_stock_list,l_stock_list_2)))
a = stock_list_dif.iloc[:,0] a.index = afor i in range(l_stock_list_2-1):    b = stock_list_dif.iloc[:,i+1]        b.index = b    a = pd.concat([a,b],axis=1)for i in range(l_stock_list_2-1):    a = stock_list_dif.iloc[:,i]     a.index = a    b = stock_list_dif.iloc[:,i+1]        b.index = b    c = pd.concat([a,b],axis=1)    c = c.fillna(88888)    d = c[(c.iloc[:,0]==88888)]    e = c[(c.iloc[:,1]==88888)]    if i == 0:        f = pd.concat([d,e])    else:        f =  pd.concat([f,e])#建立一个小database check 差异股票/剔出股票的名字# 回头补充更general的算法 
#%% download datastart_year = 2013path_df_con = "/Users/44091781/Desktop/HSIL/Daniel/3-Operation/index/"+target+"_con_row_"+str(start_year)+".xlsx"
df_con = pd.read_excel(path_df_con)code = df_con.columnsname = df_con.iloc[0,:]name_list = list(set(name)) #注意变成list 顺序会变hsi_con = df_con.iloc[2:-2,:]#%%  continue data setlist_date = stock_list_dif.columns
#change date stylea=[]for i in range(len(hsi_con)):    k = datetime.strftime(hsi_con.index[i],'%Y%m%d')    a.append(k)a = np.array(a)hsi_con.index = a.tolist()
long =len(hsi_con.loc[list_date[0]:])
# match stock codestock_code = hsi_con.columns[0:-2].valuesfor i in range(len(stock_code)):    stock_code[i] = stock_code[i][0:4]stock_code = stock_code.astype(int)hsi_con_stock = hsi_con.iloc[:,0:-2]hsi_con_stock.columns = stock_code.tolist()    
#%%
#%% function def performance(T,down,up):    def stats(wts):        port_r = np.sum(mean*wts)        port_var = np.sqrt(np.dot(wts.T, np.dot(cov, wts)))        return np.array([port_r, port_var, (port_r-rf)/port_var])
    def min_var(wts):        return stats(wts)[1]
    def min_sharpe(wts):        return -stats(wts)[2]
    #Select first train Sample    stock_code_0 = stock_list_dif[list_date[0]]    train_price_0 = hsi_con_stock[stock_code_0.values.tolist()]    train_price_0 = train_price_0[:list_date[0]]    train_price_0 = train_price_0.iloc[-T:,:]        train_return_0 = (train_price_0/train_price_0.shift(1)).dropna()    train_return_0 = train_return_0.astype(float)        train_return_0 = np.log(train_return_0)    #Cal first MVP weight    mean= train_return_0.mean()*252    cov = train_return_0.cov()*252    length = len(train_return_0.T)    wts = np.random.random(length)     wts /= np.sum(wts)    cons = ({'type': 'eq', 'fun': lambda x: np.sum(x)-1})    bnds = tuple((down, up) for x in range(len(train_return_0.columns)))    lens = len(train_return_0.columns)    opts = opt.minimize(            min_var, lens*[1./lens], method='SLSQP',            bounds=bnds, constraints=cons       )    opts    min_var_weight_0 = opts['x']    min_var_weight_0 = pd.DataFrame(min_var_weight_0)    #Cal first Max-sharp weight    cons = ({'type': 'eq', 'fun': lambda x: np.sum(x)-1})    bnds = tuple((down, up) for x in range(len(train_return_0.columns)))    lens = len(train_return_0.columns)    opts = opt.minimize(            min_sharpe, lens*[1./lens], method='SLSQP',            bounds=bnds, constraints=cons       )    opts    max_sharpe_weight_0 = opts['x']       max_sharpe_weight_0 = pd.DataFrame(max_sharpe_weight_0)        # First Test Sample    stock_code_0 = stock_list_dif[list_date[0]]    Test_price_0 = hsi_con_stock[stock_code_0.values.tolist()]    Test_price_0 = Test_price_0[list_date[0]:list_date[1]]        Test_return_0 = (Test_price_0/Test_price_0.shift(1)).dropna()    Test_return_0 = Test_return_0.astype(float)        Test_return_0 = np.log(Test_return_0)        # First accumulated return    hsi_con_stock['MVP_Return_Index'] = 0.000    hsi_con_stock['MVP_Return'] = 0.000    for r in range(len(Test_return_0)):        hsi_con_stock['MVP_Return_Index'][list_date[0]:list_date[1]][r+1]=np.dot((1+Test_return_0).cumprod() , min_var_weight_0)[r]        hsi_con_stock['MVP_Return_Index'][list_date[0]:list_date[1]][0]=1    hsi_con_stock['MVP_Return'][list_date[0]:list_date[1]] = np.log(hsi_con_stock['MVP_Return_Index'][list_date[0]:list_date[1]]/hsi_con_stock['MVP_Return_Index'][list_date[0]:list_date[1]].shift(1))
    hsi_con_stock['MAX_SHARPE_Return_Index'] = 0.000    hsi_con_stock['MAX_SHARPE_Return'] = 0.000      for r in range(len(Test_return_0)):        hsi_con_stock['MAX_SHARPE_Return_Index'][list_date[0]:list_date[1]][r+1]=np.dot((1+Test_return_0).cumprod() , max_sharpe_weight_0)[r]    hsi_con_stock['MAX_SHARPE_Return_Index'][list_date[0]:list_date[1]][0]=1    hsi_con_stock['MAX_SHARPE_Return'][list_date[0]:list_date[1]] = np.log(hsi_con_stock['MAX_SHARPE_Return_Index'][list_date[0]:list_date[1]]/hsi_con_stock['MAX_SHARPE_Return_Index'][list_date[0]:list_date[1]].shift(1))        #All Train price/return/weight output    for i in range(len(list_date)-1):        stock_code_1 = stock_list_dif[list_date[i+1]].dropna()        train_price_1 = hsi_con_stock[stock_code_1.values.tolist()]        train_price_1 = train_price_1[:list_date[i+1]]        train_price_1 = train_price_1.iloc[-T:,:]        train_price_0 = pd.concat([train_price_0,train_price_1],axis = 0)            train_price_1 = train_price_1.fillna(1) #把停牌的/没数据的都放为1，return为0            train_return_1 = (train_price_1/train_price_1.shift(1)).dropna()        train_return_1 =  train_return_1.astype(float)           train_return_1 =  np.log(train_return_1)           train_return_0 = pd.concat([train_return_0,train_return_1],axis = 0)    #calculate  MVP weight        mean = train_return_1.mean()*252        cov = train_return_1.cov()*252        cons = ({'type': 'eq', 'fun': lambda x: np.sum(x)-1})        bnds = tuple((down, up) for x in range(len(train_return_1.columns)))# can change!!!!        lens = len(train_return_1.columns)        opts = opt.minimize(                min_var, lens*[1./lens], method='SLSQP',                bounds=bnds, constraints=cons        )        opts        min_var_weight_1 = opts['x']          min_var_weight_1 = pd.DataFrame(min_var_weight_1)        min_var_weight_0 = pd.concat([min_var_weight_0,min_var_weight_1],axis = 1)#calculate Max-sharp weight        cons = ({'type': 'eq', 'fun': lambda x: np.sum(x)-1})        bnds = tuple((down, up) for x in range(len(train_return_1.columns)))# can change!!!!        lens = len(train_return_1.columns)        opts = opt.minimize(                min_sharpe, lens*[1./lens], method='SLSQP',                bounds=bnds, constraints=cons        )        opts        max_sharpe_weight_1 = opts['x']          max_sharpe_weight_1 = pd.DataFrame(max_sharpe_weight_1)        max_sharpe_weight_0 = pd.concat([max_sharpe_weight_0,max_sharpe_weight_1],axis = 1)    
    min_var_weight_0 = round(min_var_weight_0,3)    max_sharpe_weight_0 = round(max_sharpe_weight_0,3)
    min_var_weight_0.columns = list_date    max_sharpe_weight_0.columns = list_date# calculate continual test return    for i in range(len(list_date)-2):        stock_code_1 = stock_list_dif[list_date[i+1]].dropna()        Test_price_1 = hsi_con_stock[stock_code_1.values.tolist()]        Test_price_1 = Test_price_1[list_date[i+1]:list_date[i+2]]        Test_price_0 = pd.concat([Test_price_0,Test_price_1],axis = 0)                Test_return_1 = (Test_price_1/Test_price_1.shift(1)).iloc[1:,:]        Test_return_1 = Test_return_1.fillna(1)        Test_return_1 = Test_return_1.astype(float)            Test_return_1 = np.log(Test_return_1)        Test_return_0 = pd.concat([Test_return_0,Test_return_1],axis = 0)                for r in range(len(Test_return_1)):            hsi_con_stock['MVP_Return_Index'][list_date[i+1]:list_date[i+2]][r+1]=np.dot((1+Test_return_1).cumprod() , min_var_weight_0[list_date[i+1]].dropna())[r]        hsi_con_stock['MVP_Return_Index'][list_date[i+1]:list_date[i+2]][0]=1        hsi_con_stock['MVP_Return'][list_date[i+1]:list_date[i+2]][1:] = np.log(hsi_con_stock['MVP_Return_Index'][list_date[i+1]:list_date[i+2]]/hsi_con_stock['MVP_Return_Index'][list_date[i+1]:list_date[i+2]].shift(1)).iloc[1:]                for r in range(len(Test_return_1)):            hsi_con_stock['MAX_SHARPE_Return_Index'][list_date[i+1]:list_date[i+2]][r+1]=np.dot((1+Test_return_1).cumprod() , max_sharpe_weight_0[list_date[i+1]].dropna())[r]        hsi_con_stock['MAX_SHARPE_Return_Index'][list_date[i+1]:list_date[i+2]][0]=1        hsi_con_stock['MAX_SHARPE_Return'][list_date[i+1]:list_date[i+2]][1:]  = np.log(hsi_con_stock['MAX_SHARPE_Return_Index'][list_date[i+1]:list_date[i+2]]/hsi_con_stock['MAX_SHARPE_Return_Index'][list_date[i+1]:list_date[i+2]].shift(1)).iloc[1:]#calculate accumulated return    hsi_con_stock['MVP_Accumulate_Index'] = 0.000     hsi_con_stock['MVP_Accumulate_Index'] = (1+ hsi_con_stock['MVP_Return']).cumprod()    hsi_con_stock['MAX_SHARPE_Accumulate_Index'] = 0.000    hsi_con_stock['MAX_SHARPE_Accumulate_Index'] = (1+ hsi_con_stock['MAX_SHARPE_Return']).cumprod()#total Compare    final_hsi_con = hsi_con_stock[list_date[0]:list_date[-1]]    final_hsi_con = pd.concat([final_hsi_con,hsi_con.iloc[:,-2:]],join='inner',axis=1)    final_hsi_con['HSI_return']=0.000    final_hsi_con['HSEWI_return'] = 0.000    final_hsi_con['HSI_Accumulate_Index'] =0.000    final_hsi_con['HSEWI_Accumulate_Index'] = 0.000        final_hsi_con['HSI_return'] = np.log((final_hsi_con['HSI.HI']/final_hsi_con['HSI.HI'].shift(1)).astype(float))    final_hsi_con['HSEWI_return'] = np.log((final_hsi_con['HSEWI.HI']/final_hsi_con['HSEWI.HI'].shift(1)).astype(float))    final_hsi_con['HSI_Accumulate_Index'] = (1+ final_hsi_con['HSI_return']).cumprod()    final_hsi_con['HSEWI_Accumulate_Index'] = (1+ final_hsi_con['HSEWI_return']).cumprod()        a=[]        for i in range(len(final_hsi_con)):        k = datetime.strptime(final_hsi_con.index[i],'%Y%m%d')        a.append(k)    a = np.array(a)    final_hsi_con.index = a.tolist()        #performance judge    perm = pd.DataFrame([np.nan] * np.ones((4,6)))    perm.columns = ['Er','Std','Sharpe-Ratio','T','Down','Up']    perm.index = ['MVP','Max_Shap','HSI','Equal']    perm_list =  ['MVP_Return','MAX_SHARPE_Return','HSI_return','HSEWI_return']    for i in range(4):        perm.iloc[i,0]=final_hsi_con[perm_list[i]].mean()*252        perm.iloc[i,1]=final_hsi_con[perm_list[i]].std()*np.sqrt(251)        perm.iloc[i,2]=final_hsi_con[perm_list[i]].mean()*252/(final_hsi_con[perm_list[i]].std()*np.sqrt(251))        perm.iloc[i,3]=T        perm.iloc[i,4]=down         perm.iloc[i,5]=up    return perm#%%T=246rf = 0.005performance_0 = performance(T,0.005,0.1).iloc[2:4,:]for i in range(11,51):    up = i/500    a =  performance(T,0.005,up).iloc[0:2,:]    performance_0 = pd.concat([performance_0,a],axis=0)
#MVP CheckSr_MVP = performance_0.loc['MVP']Sr_MVP.index = Sr_MVP.iloc[:,-1]
plt.figure(1,figsize=(10, 6)) line1 = plt.plot(Sr_MVP.index,Sr_MVP.iloc[:,0:1],label=['Er'])line2 = plt.plot(Sr_MVP.index,Sr_MVP.iloc[:,1:2],label=[['Std']])plt.grid(True)  plt.legend( loc = "upright")plt.figure(2,figsize=(10, 6)) line3 = plt.plot(Sr_MVP.index,Sr_MVP.iloc[:,2:3],label=[['Sharpe-Ratio']])plt.grid(True)  plt.legend( loc = "upright")
#Max Sharp CheckMax_Shap = performance_0.loc['Max_Shap']Max_Shap.index = Max_Shap.iloc[:,-1]
plt.figure(1,figsize=(10, 6)) line1 = plt.plot(Max_Shap.index,Max_Shap.iloc[:,0:1],label=['Er'])line2 = plt.plot(Max_Shap.index,Max_Shap.iloc[:,1:2],label=[['Std']])plt.grid(True)  plt.legend( loc = "upright")plt.figure(2,figsize=(10, 6)) line3 = plt.plot(Max_Shap.index,Max_Shap.iloc[:,2:3],label=[['Sharpe-Ratio']])plt.grid(True)  plt.legend( loc = "upright")
#%% down-up 同时changeT=246rf = 0.005performance_0 = performance(T,0.005,0.1).iloc[2:4,:]for uu in range(11,51):    up = uu/500    for dd in range(0,5):        down = dd/500        a =  performance(T,down,up).iloc[0:2,:]        performance_0 = pd.concat([performance_0,a],axis=0)# MVP = performanceSharpe_Ratio_MVP = performance_0.loc['MVP']longup = (51-11)longdown = (5-0)Sharpe_Ratio_MVP_2 = pd.DataFrame([np.nan]* np.ones((longup,longdown)))Sharpe_Ratio_MVP_2.index = (np.linspace(11,50,num=40)/500).round(3)Sharpe_Ratio_MVP_2.columns = (np.linspace(0,4,num=5)/500).round(3)for a in range(longup):    for b in range(longdown):        Sharpe_Ratio_MVP_2.iloc[a,b] = Sharpe_Ratio_MVP.iloc[b+a,2]
Expect_Return_MVP_2 = pd.DataFrame([np.nan]* np.ones((longup,longdown)))Expect_Return_MVP_2.index = (np.linspace(11,50,num=40)/500).round(3)Expect_Return_MVP_2.columns = (np.linspace(0,4,num=5)/500).round(3)for a in range(longup):    for b in range(longdown):        Expect_Return_MVP_2.iloc[a,b] = Sharpe_Ratio_MVP.iloc[b+a,0]
Std_MVP_2 = pd.DataFrame([np.nan]* np.ones((longup,longdown)))Std_MVP_2.index = (np.linspace(11,50,num=40)/500).round(3)Std_MVP_2.columns = (np.linspace(0,4,num=5)/500).round(3)for a in range(longup):    for b in range(longdown):        Std_MVP_2.iloc[a,b] = Sharpe_Ratio_MVP.iloc[b+a,1]                #sharp-ratio  MAX Sharp_ratioSharpe_Ratio_MSP = performance_0.loc['Max_Shap']longup = (51-11)longdown = (5-0)Sharpe_Ratio_MSP_2 = pd.DataFrame([np.nan]* np.ones((longup,longdown)))Sharpe_Ratio_MSP_2.index = (np.linspace(11,50,num=40)/500).round(3)Sharpe_Ratio_MSP_2.columns = (np.linspace(0,4,num=5)/500).round(3)for a in range(longup):    for b in range(longdown):        Sharpe_Ratio_MSP_2.iloc[a,b] = Sharpe_Ratio_MSP.iloc[b+a,2]        Expect_Return_MSP_2 = pd.DataFrame([np.nan]* np.ones((longup,longdown)))Expect_Return_MSP_2.index = (np.linspace(11,50,num=40)/500).round(3)Expect_Return_MSP_2.columns = (np.linspace(0,4,num=5)/500).round(3)for a in range(longup):    for b in range(longdown):        Expect_Return_MSP_2.iloc[a,b] = Sharpe_Ratio_MSP.iloc[b+a,0]
Std_MSP_2 = pd.DataFrame([np.nan]* np.ones((longup,longdown)))Std_MSP_2.index = (np.linspace(11,50,num=40)/500).round(3)Std_MSP_2.columns = (np.linspace(0,4,num=5)/500).round(3)for a in range(longup):    for b in range(longdown):        Std_MSP_2.iloc[a,b] = Sharpe_Ratio_MSP.iloc[b+a,1]                #def   热点图import seaborn as snssns.heatmap(Sharpe_Ratio_MVP_2,annot=True)plt.show()sns.heatmap(Expect_Return_MVP_2,annot=True)plt.show()sns.heatmap(Std_MVP_2,annot=True)plt.show()
sns.heatmap(Sharpe_Ratio_MSP_2,annot=True)plt.show()sns.heatmap(Expect_Return_MSP_2,annot=True)plt.show()sns.heatmap(Std_MSP_2,annot=True)plt.show()
